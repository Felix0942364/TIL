# Feb 9
String Searching Algorithms.
[https://en.wikipedia.org/wiki/String-searching_algorithm](https://en.wikipedia.org/wiki/String-searching_algorithm)

## Introduction
In computer science, string-searching algorithms, sometimes called string-matching algorithms are an important clss of string algorithms that try to find a place where one or several strings(also called patterns) are found within a larger string or text.
A basic example of string searching is when the pattern and searched text are arrays of elements of an alphabet (finite set) Σ.  Σ may be a human language alphabet, for example, the letters A~Z and other applications may use a binary alphabet(Σ={0,1}) or as DNA alphabet(Σ={A,C,G,T}) in bioinformatics.
In practice, the method of feasible string-search algorithm amy be affected by the string encoding. In particular, if a variable-width encoding is in use, then it may be slower to find the Nth character, perhaps requiring time proportional to N. this may significantly slow some search algorithms. one of many possible solutions is to search for the sequence of code units instead, but doing so may produce false matches unless the encoding is specifically designed to avoid it.

## Overview
The most basic case of string seraching involves on(often very long) string, sometimes called the haystack, and one (often very short) string, sometimes called the needle. The goal is to find one or more occurrences of the needle within the haystack. For example, one might search for to within:
```
Some books are to be tasted, others to be swallowed, and some to be chewed and digested.
```
One might request the first occurrence of "to", which is the fourth word; or all occurrences, of which there are 3; or the last, which is the fifth word from the end.
Very commonly, however, various constraints are added. For example, one might want to match the "needle" only where in consists of one(or more) complete words -- perhaps defined as not having other letters immediately adjacent on either sid. In that case a search for "hew" or "low" should fail for the example sentence above, even though those literal strings do occur.
Another common example involves "normalization". For many purposes, a search for a phrase such as "to be" shoud succeed even in places where there is something else intervening between the "to" and the "be"
- More than one space
- Other "whitespace" characters such as tabs, non-breaking spaces, line-breaks, etc.
- Less commonly, a hyphen or soft hyphen
- In structured texts, tags or even arbitrarily large but "parenthetical" things such as footnotes, list-nubers or other marker, embedded images, and so on.

Many symbol systems include characters that are synonymous(at least for some purposes):
- Latin-based  alphabets distinguis lower-case from upper-case, but for many purposes string search is expected to ignore the distiction.
- Many languages include ligatures, where one composite character is equivalent to two or more other characters.
- Many writing systems involve diacritical marks such as accents or vowel points, which may vary in their usage, or be of varying importance in matching.
- DNA swequences can invove non-coding segments which may be ignored for some purposes, or polymorphisms that lead to no chagne in the encoded proteins, which may not count as a true difference for some other purposes.
- Some languages have rules where a different character or form of character must be used at the star, middle, or end of words.
Finally for strings that represent natural language, aspects of the language itself become invovled. For example one mgith wish to find all occurrences of a "word" despite it having alternate spellings, prefixes or suffixes, etc.
Another more complex type of search is regular expression searching, where the user constructs a pattern of characters or other symbols, and any match to the patter should fulfill the serach. For example, to catch both the Amercian English word "color" and the British equivalent "colour", instead of search for two different literal strings, one might use a regular expression such as:
```
colou?r
```
where the "?" conventionally makes the rpeceding character ("u") optional.
This article mainly discusses algorithms for the simpler kinds of string searching.
A similar problem in the field of bioinformatics and genomics is the maximal exact matching(MEM). Given two strings, MEMs are common substrings that cannot be extended left or right without causing a mismatch.

## Examples of search algorithms
### Naive string serach
A simple and inefficient way to see where one string occurs inside another is to check at each index, one by one. First, we see if there's a copy of the needle starting at the first character of the haystackk; if not, we look to see if there's a copy of the needle starting at the second character of the haystack, and so forth. In the normal case, we only have to look at one or two characters for each wrogn position to see that is a wrong position, so in the average case, this takes O(n+m) steps, where n is the length of the haystack and m is the length of the needle; but in the worst case, each for a string like "aaaab" in a string like "aaaaaaaaaaaaaaab", it takes O(nm)

### Finite-state-automaton-based search
In this approach backtracking is avoided by constructing a deterministic finite automato(DFA) that recognizes stored search string. These are expenseive to construct --- they are usually created using the powerset construction -- but are very quick to use for [example](https://en.wikipedia.org/wiki/File:DFA_search_mommy.svg), the DFA shown to the right recognizes the word "MOMMY". This approach is frequently generalized in parctice to search for arbitrary regular expressions.

### Stubs
Knuth-Morris-Pratt(KMP) computes a DFA that recognizes inputs with the string to search for as a suffix, Boyer-Moore starts searching from the end of the neelde, so it can usually jum ahead a whole needle-length at each step. Baeza-Yates keeps track of whether the previous *j* characters were a prefix of the serach string, and is therefore adaptable to [fuzzy string searching](https://en.wikipedia.org/wiki/Approximate_string_matching). The [bitap algorithm](https://en.wikipedia.org/wiki/Bitap_algorithm) is an application of Baeza-Yates approach.

### Index methods
Faster serach algorithms preprocess the text. After building a substring index, for example a suffix tree or suffix array, the occurrences of a pattern can be found quickly. As an example, a suffix tree can be built in O(n) time, and all *z* occurrences of a pattern can be found in underneath them. The latter can be accompished by running a DFS algorithm form the root of the suffix tree.

### Other variants
Some search methods, for instance [trigram search](https://en.wikipedia.org/wiki/Trigram_search)

## Classification of serach algorithms
### Classification by a number of patterns
The various algorithms can be classified by the number of patterns each used

#### Single-pattern algorithms
In the following compiation, *m* is the length of the pattern, *n* the length of the serachable text, and *k* = |Σ| is the size of the alphabet.

|Algorithms|Preprocessing time|Matching time|Space|
|---|---|---|---|
|Naive Algorithm|none|Θ(mn)|none|
|Knuth-Morris-Pratt|Θ(m)|Θ(n)|Θ(m)|
|Boyer-Moore|Θ(m+k)|Ω(n/m) at best, O(mn) at worst|Θ(k)|
|Two-way algorithm|Θ(m)|O(n)|O(1)|
|Backward Non-Deterministic DAWG Matching(BNDM)|O(m)|Ω(n/m) at best, O(mn) at worst|---|
|Backward Oracle Matching(BOM)|O(m)|O(mn)|---|
The [Boyer-Moore](https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore_string-search_algorithm) string-searching algorithm has been the standard benchmark for the practical string-serach literature.


#### Algorithms using a finite set of patterns
In the following compiation, *m* is the length of the pattern, *n* the length of the serachable text, and *k* = |Σ| is the size of the alphabet.

|Algorithms|Preprocessing time|Matching time|Space|
|---|---|---|---|
|Naive Algorithm|none|Θ(mn)|none|
|Knuth-Morris-Pratt|Θ(m)|Θ(n)|Θ(m)|
|Boyer-Moore|Θ(m+k)|Ω(n/m) at best, O(mn) at worst|Θ(k)|
|Two-way algorithm|Θ(m)|O(n)|O(1)|
|Backward Non-Deterministic DAWG Matching(BNDM)|O(m)|Ω(n/m) at best, O(mn) at worst|---|
|Backward Oracle Matching(BOM)|O(m)|O(mn)|---|


Algorithm	Extension of	Preprocessing time	Matching time[4]	Space
Aho–Corasick	Knuth–Morris–Pratt	Θ(m)	Θ(n + o)	Θ(m)
Commentz-Walter	Boyer-Moore	Θ(m)	Θ(M * n) worst case
sublinear in average[9]	Θ(m)
Set-BOM	Backward Oracle Matching			
Algorithms using an infinite number of patterns
Naturally, the patterns can not be enumerated finitely in this case. They are represented usually by a regular grammar or regular expression.

Classification by the use of preprocessing programs
Other classification approaches are possible. One of the most common uses preprocessing as main criteria.

Classes of string searching algorithms[10]
Text not preprocessed	Text preprocessed
Patterns not preprocessed	Elementary algorithms	Index methods
Patterns preprocessed	Constructed search engines	Signature methods :[11]
Classification by matching strategies
Another one classifies the algorithms by their matching strategy:[12]

- Match the prefix first (Knuth–Morris–Pratt, Shift-And, Aho–Corasick)
- Match the suffix first (Boyer–Moore and variants, Commentz-Walter)
- Match the best factor first (BNDM, BOM, Set-BOM)
- Other strategy (Naïve, Rabin–Karp)